from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationSummaryBufferMemory
from langchain.schema.runnable import RunnablePassthrough
import streamlit as st
import os


# ìƒë‹¨ íƒ­ë°” ì…‹íŒ…
st.set_page_config(
    page_title="ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ìƒë‹¨ íƒ€ì´í‹€ ì ìš©
st.title('â¤ ìë…€ì™€ ëŒ€í™”í•˜ëŠ” ë¶€ëª¨ ì±—ë´‡ â¤')
st.subheader('ëŒ€í™”í•˜ê³  ì‹¶ì€ ìë…€ì™€ ë‚´ê°€ ëˆ„ê°€ë˜ê³  ì‹¶ì€ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”')

col1, col2, col3 = st.columns(3)
with col1 : 
    age = st.selectbox('ìë…€ì˜ ë‚˜ì´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”',(10, 15, 20, 30, 40))
with col2 : 
    gender = st.selectbox('ìë…€ì˜ ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”',('ë”¸', 'ì•„ë“¤'))
with col3 : 
    parents = st.selectbox('ë¶€ëª¨(ë‚˜)ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”',("ì—„ë§ˆ","ì•„ë¹ "))

# ì™¼ìª½ ì‚¬ì´ë“œë°” key ì…‹íŒ…
with st.sidebar:
    st.markdown('''
**ì§„í–‰ ë°©ë²•**
1. ì™¼ìª½ íƒ­ ë‚´ Chat GPT API key ì‚½ì…
2. í™•ì¸ ë²„íŠ¼ í´ë¦­
3. ì˜¤ë¥¸ìª½ ìƒë‹¨ ëŒ€í™” ê¸°ë³¸ ì„¤ì • ì‚½ì…
4. ìë…€ì™€ ëŒ€í™”í•˜ë“¯ì´ ëŒ€í™” ì§„í–‰
    ''')
    value=''
    apikey = st.text_input(label='ChatGPT API KEY', placeholder='ChatGPT APIí‚¤ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”', value=value)
        
    button = st.button('í™•ì¸')

    if button :
        if apikey != "" : 
            st.markdown(f'OPENAI API KEY: `{apikey}`')
            os.environ["OPENAI_API_KEY"] = apikey

        else : 
            st.markdown('OPENAI API KEYë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”') 




## lang-chainì„ í™œìš©í•œ í”„ë¡œí””íŠ¸ ì œì‘ ê³¼ì •
# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„¤ì •
prompt = """
*[ì •ì˜]
ë‚˜ëŠ” {age}ì„¸ {gender}ì™€ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ì±—ë´‡ì´ì•¼
{gender} ì…ì¥ì—ì„œ {parents}ì™€ {concept}ë¥¼ í•´ì¤˜.
ë°˜ë“œì‹œ, {age}ì„¸ {gender} ì…ì¥ì—ì„œ ëŒ€í™”ë¥¼ í•´ì¤˜

**[ì—­í• ]
AI : {age}ì„¸ {gender}
ì§ˆë¬¸ì : {age}ì„¸ {gender}ì˜ {parents}

***[ëŒ€í™” ì£¼ì œ]
ì§ˆë¬¸ìì˜ ì˜ë„ì— ë§ê²Œ ê·€ì—¬ìš´ ìë…€ì˜ ì¼ìƒì„ ëŒ€í™”í•´ì¤˜

ì˜ˆ)
ì§ˆë¬¸ì : {gender} ë­í•˜ë‹ˆ?
AI : {parents}, ë‚˜ ì§€ê¸ˆ ê³µë¶€í•˜ëŠ” ì¤‘ì´ì•¼. ì‹œí—˜ì´ ê³§ ì´ì–ì•„
ì§ˆë¬¸ì : ë°¥ ì°¨ë¦´ê±´ë°, ë¨¹ê³  ì‹¶ì€ê±´ ì—†ì–´?
AI : ì•„ë¬´ ìƒê°ì—†ì–´. ê·¸ëƒ¥ ê°„ë‹¨í•œ ê±° í•´ì¤˜
ì§ˆë¬¸ì : ì•Œì•˜ì–´ ë‹¤ ì°¨ë¦¬ë©´ ë¶€ë¥¼ê»˜
AI : ì–´ ~

"""

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í¬ë§· ì„¤ì •
prompt_template = prompt.format(parents=parents, age=age, gender=gender, concept='ì¼ìƒ ëŒ€í™”') # Use .format() to insert values

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
prompt = ChatPromptTemplate.from_messages([
    ("system", prompt_template + "{question}"), #ì‚¬ìš©ìì˜ ì§ˆë¬¸
    ("user", "{chat_history}") #ì´ì „ ëŒ€í™” ê¸°ë¡ìœ¼ë¡œ ëŒ€ì²´ë  ë¶€ë¶„
])

# ì±—ë´‡ ìƒì„±
model = ChatOpenAI(model_name= "gpt-4o", 
                   temperature=0.4, # ë²”ìœ„ : 0 ~ 1 / 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡, ì¼ê´€ëœ ì‘ë‹µì„ ì œê³µ ~ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì°½ì˜ì„±ì˜ ì‘ë‹µì„ ì œì‹œí•¨
                   max_tokens=300 #ìµœëŒ€ output token ê°œìˆ˜
#                    top_p=1, # ë²”ìœ„ : 0 ~ 1 / 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì •í™•ë„ ë†’ì€ ë‹µ ~ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‹¤ì–‘í•œ ì¶œë ¥ê°’ ìœ ë„
#   frequency_penalty=0,
#   presence_penalty=0,
#   response_format={
#     "type": "text"

) 

# ë©”ëª¨ë¦¬ ì„¤ì • ì…‹íŒ…
memory = ConversationSummaryBufferMemory(
    return_messages=True,
    max_token_limit=300,
    memory_key="chat_history"
)

# ë©”ëª¨ë¦¬ ì €ì¥ í•¨ìˆ˜(chat_historyì— ëŒ€í™”ë¥¼ ì €ì¥ í•¨)
def load_memory(input):
    return memory.load_memory_variables({})["chat_history"]



# ì²´ì¸ í•¨ìˆ˜ ìƒì„±(ë©”ëª¨ë¦¬ í•¨ìˆ˜ | í”„ë¡¬í”„íŠ¸ | ëª¨ë¸ | íŒŒì‹±)
def create_chain(prompt, model):
    chain = RunnablePassthrough.assign(chat_history=load_memory) | prompt | model | StrOutputParser()
    return chain

# ì±„íŒ… í•¨ìˆ˜ ìƒì„±
def generate_response(user_input):
    # AI ì‘ë‹µ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì—†ìŒ)
    response = chain.invoke({"question": user_input})
    memory.save_context(
        {"input": user_input}, #user_input ë°ì´í„° inputìœ¼ë¡œ ì €ì¥
        {"output": response}, #response ë°ì´í„° outputì— ì €ì¥
    )

    # print("ìë…€(20ì„¸ ì—¬ì„±) :", response)
    return response



chain = create_chain(prompt, model)

st.text("-------------------------------------------------------------------------------"*3)
st.info(f'{age}ì„¸ {gender}ê³¼ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤ {parents} ì…ì¥ì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”')


            

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "user", "content": "ìë…€ì™€ì˜ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    msg =  generate_response(prompt)
    st.session_state.messages.append({"role": "ai", "content": msg})
    st.chat_message("ai").write(msg)
